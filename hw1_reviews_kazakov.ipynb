{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание 1 по теме: определение тональной окраски отзыва с помощью словаря"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импорт необходимых модулей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fake_useragent import UserAgent\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "import random\n",
    "from random import randint\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "import collections\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем UserAgent, который создаёт имитацию браузера, что бы нас не поймали. Для этого же time.sleep(1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "ua = UserAgent(verify_ssl=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функции для выкачивания отзывов и оценок (только 1/5, 2/5 и 5/5, чтобы можно было поделить на две группы) пользователей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_parse(new_href):\n",
    "    while new_href is not None:\n",
    "        rest_url = main_url + new_href\n",
    "        time.sleep(1)\n",
    "        req = requests.get(rest_url, headers={'User-Agent': ua.random})\n",
    "        rest = req.text\n",
    "        soup = BeautifulSoup(rest, 'html.parser')\n",
    "        new_href = soup.find('a', {'class': 'nav next ui_button primary cx_brand_refresh_phase2'})\n",
    "        if new_href is not None:\n",
    "            new_href = new_href['href']\n",
    "        review_blocks = soup.find_all('div', {'class': 'ui_column is-9'})\n",
    "        for r in review_blocks:\n",
    "            com = comments(str(r))\n",
    "            if com[1] == 5:\n",
    "                good.append(com[0])\n",
    "            elif com[1] == 1 or com[1] == 2:\n",
    "                bad.append(com[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comments(rev):\n",
    "    soup = BeautifulSoup(rev, 'html.parser')\n",
    "    text = soup.find('p', {'class': 'partial_entry'}).get_text()\n",
    "    mark = soup.find('span')\n",
    "    mark = mark['class'][1]\n",
    "    mark = int(re.sub(r'bubble_(\\d)0', r'\\1', mark))\n",
    "    return text, mark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С сайта https://www.tripadvisor.ru выкачиваем отзывы о тёх ресторанах сети \"Тануки\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_url = 'https://www.tripadvisor.ru'\n",
    "good = []\n",
    "bad = []\n",
    "first = ['/Restaurant_Review-g298484-d3775519-Reviews-Tanuki-Moscow_Central_Russia.html',\n",
    "        '/Restaurant_Review-g298484-d3236588-Reviews-Tanuki-Moscow_Central_Russia.html',\n",
    "        '/Restaurant_Review-g298484-d3200244-Reviews-Tanuki-Moscow_Central_Russia.html']\n",
    "for f in first:\n",
    "    page_parse(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Всего положительных и отрицательных отзывов для составления списков — по 90. Делим выборки. Random, чтобы отзывы о разных ресторанах, оставленные в разное время, перемешались. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(good_list)\n",
    "random.shuffle(bad_list)\n",
    "good_list = good[0:90]\n",
    "bad_list = bad[0:90]\n",
    "good_test = good[90:105]\n",
    "bad_test = bad[90:105]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Токенизация, лемматизация, приведение к нижнему регистру."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(text):\n",
    "    text = [w.lower() for w in word_tokenize(text) if w.isalpha()]\n",
    "    new_lst = []\n",
    "    for elem in text:\n",
    "        new_lst.append(morph.parse(elem)[0].normal_form)\n",
    "    return new_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Составление двух списков уникальных слов из отзывов положительной и отрицательной групп. Фильтр отсеивает шум (стоп-слова и слова, которые встречаются 1 раз)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_lemmas(lst):\n",
    "    if type(lst) == list:\n",
    "        lst = ' '.join(lst)\n",
    "    new_lst = preproc(lst)\n",
    "    count = collections.Counter(new_lst).most_common()\n",
    "    final_lst = []\n",
    "    for c in count:\n",
    "        if c[1] > 1:\n",
    "            final_lst.append(c[0])\n",
    "    sw = stopwords.words('russian')\n",
    "    final_lst = [w for w in final_lst if w not in sw]\n",
    "    return final_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_list = set(tokens_lemmas(good_list))\n",
    "bad_list = set(tokens_lemmas(bad_list))\n",
    "both = good_list & bad_list\n",
    "good_list = list(good_list - both)\n",
    "bad_list = list(bad_list - both)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция определения тональности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tonality(sent):\n",
    "    sent_lst = preproc(sent)\n",
    "    k = 0\n",
    "    for w in sent_lst:\n",
    "        if w in good_list:\n",
    "            k += 1\n",
    "        elif w in bad_list:\n",
    "            k -= 1\n",
    "    if k > 0:\n",
    "        return 1\n",
    "    elif k < 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return randint(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подсчёт accuracy с помощью тестовой выборки (15 положительных и 15 отрицательных отзывов). **Итоговый результат: 0,8.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8\n"
     ]
    }
   ],
   "source": [
    "real = []\n",
    "test = []\n",
    "for g in good_test:\n",
    "    real.append(1)\n",
    "    test.append(tonality(g))\n",
    "for b in bad_test:\n",
    "    real.append(0)\n",
    "    test.append(tonality(b))\n",
    "print('Accuracy =', round(accuracy_score(real, test), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Улучшение программы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Можно смотреть не собственно слова, а их векторные представления (с помощью предобученной модели RusVectores, так как обучать модель для этой задачи незачем). Оценочная лексика может разбиться на группы в зависимоти от её тональности. В тестовой выборке мы могли бы сравнивать не слова, а векторые представления. Это было бы полезно в случае с синонимами, то есть, если у нас в списке есть слово \"отвратительный\", но нет \"ужасный\", то для нашей программы слово \"ужасный\" теряется, а вот векторные представления этих слов были бы достаточно близки, что помогло бы в опредлении тональности отзыва.\n",
    "2. С помощью нейросетей можно провести оценку тональности эмодзи, которых, кстати, в отзывах очень много."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
